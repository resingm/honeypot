{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load utils.py\n",
    "from datetime import datetime\n",
    "\n",
    "import ipaddress as ip\n",
    "\n",
    "log_ts = None\n",
    "\n",
    "def reset_delta():\n",
    "    global log_ts\n",
    "    \n",
    "    ts = datetime.now()\n",
    "    log_ts = [ts, ts]\n",
    "    \n",
    "\n",
    "# Logging utils\n",
    "def log(msg, delta=True):\n",
    "    global log_ts\n",
    "    \n",
    "    curr_ts = datetime.now()\n",
    "    \n",
    "    # init logging\n",
    "    if log_ts is None:\n",
    "        reset_delta()\n",
    "        out(log_ts, \"Logging initialized.\", delta=False)\n",
    "    \n",
    "    log_ts[1] = curr_ts\n",
    "    out(log_ts, msg, delta=delta)\n",
    "       \n",
    "    # set new logging timestamps\n",
    "    log_ts = [log_ts[1], datetime.now()]\n",
    "    \n",
    "    \n",
    "def out(ts, msg, delta=True):\n",
    "    fmt = None\n",
    "    args = None\n",
    "    \n",
    "    if delta:\n",
    "        fmt = '[%s | +%s s] %s'\n",
    "        args = (str(ts[1]), (ts[1] - ts[0]).total_seconds(), msg)\n",
    "    else:\n",
    "        fmt = '[%s] %s'\n",
    "        args = (str(ts[1]), msg)\n",
    "        \n",
    "    print(fmt % args)\n",
    "    \n",
    "\n",
    "def str2ip(s):\n",
    "    return int(ip.IPv4Address(s))\n",
    "\n",
    "def ip2str(i):\n",
    "    return str(ip.IPv4Address(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-05-28 11:24:00.544335] Logging initialized.\n",
      "[2021-05-28 11:24:00.544329 | +-6e-06 s] Finished imports.\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init('/opt/spark')\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "log('Finished imports.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some static variables\n",
    "\n",
    "CA = 'campus'\n",
    "CL = 'cloud'\n",
    "RE = 'residential'\n",
    "\n",
    "CA_CL = CA + CL\n",
    "CA_RE = CA + RE\n",
    "CL_RE = CL + RE\n",
    "ALL = CA + CL + RE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-05-28 11:24:10.926942 | +10.382613 s] Created Session: <pyspark.sql.session.SparkSession object at 0x7fe616efd0b8>\n"
     ]
    }
   ],
   "source": [
    "# Init variables\n",
    "\n",
    "SPARK_URI = \"spark://10.10.10.80:7077\"\n",
    "SPARK_APP = \"First steps research project\"\n",
    "\n",
    "\"\"\"\n",
    "spark = SparkSession.builder \\\n",
    "    .master(SPARK_URI) \\\n",
    "    .appName(SPARK_APP) \\\n",
    "    .config(conf=SparkConf()) \\\n",
    "    .getOrCreate()\n",
    "\"\"\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(SPARK_URI) \\\n",
    "    .appName(SPARK_APP) \\\n",
    "    .config(\"spark.driver.host\", \"10.10.10.80\") \\\n",
    "    .config(\"spark.jars\", \"postgresql-42.2.20.jar\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "log(f\"Created Session: {str(spark)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- origin: string (nullable = true)\n",
      " |-- origin_id: integer (nullable = true)\n",
      " |-- sync_ts: timestamp (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- ip: string (nullable = true)\n",
      " |-- username: string (nullable = true)\n",
      " |-- raw: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- sync_ts: timestamp (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- asn: integer (nullable = true)\n",
      " |-- asname: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- ip: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- ip: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- org: string (nullable = true)\n",
      " |-- postal: string (nullable = true)\n",
      " |-- timezone: string (nullable = true)\n",
      "\n",
      "[2021-05-28 11:24:17.418111 | +6.491169 s] Loaded dataframes for log and dataplane.\n"
     ]
    }
   ],
   "source": [
    "PG_URL=\"jdbc:postgresql://localhost:5432/honeypot\"\n",
    "PG_USER=\"max\"\n",
    "PG_PASS=\"K8yrQKMD151\"\n",
    "\n",
    "options = {\n",
    "    \"url\" : PG_URL,\n",
    "    \"user\" : PG_USER,\n",
    "    \"password\" : PG_PASS,\n",
    "    \"driver\" : \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "dfLog = spark.read.format(\"jdbc\").options(\n",
    "    dbtable=\"log\",\n",
    "    **options\n",
    "    #url=PG_URL,\n",
    "    #dbtable=\"log\",\n",
    "    #user=PG_USER,\n",
    "    #password=PG_PASS,\n",
    "    #driver=\"org.postgresql.Driver\"\n",
    ").load()\n",
    "\n",
    "dfLog.printSchema()\n",
    "\n",
    "dfDataplane = spark.read.format(\"jdbc\").options(\n",
    "    dbtable=\"dataplane\",\n",
    "    **options\n",
    ").load()\n",
    "\n",
    "dfDataplane.printSchema()\n",
    "\n",
    "dfIp = spark.read.format(\"jdbc\").options(\n",
    "    dbtable=\"ip\",\n",
    "    **options\n",
    ").load()\n",
    "\n",
    "dfIp.printSchema()\n",
    "\n",
    "#recs = dfLog.select('*').where(\"username='ubuntu'\").collect()\n",
    "#recs = dfLog.select('id', 'origin', 'origin_id', 'timestamp', 'category', 'ip', 'username').where(\"username='ubuntu'\").collect()\n",
    "\n",
    "#log(f\"Lenght of records: {len(recs)}\")\n",
    "\n",
    "log(\"Loaded dataframes for log and dataplane.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-05-28 11:24:53.963663 | +36.545552 s] CAMPUS:                        2355\n",
      "[2021-05-28 11:25:08.229606 | +14.265943 s] CLOUD:                         3396\n",
      "[2021-05-28 11:25:16.925119 | +8.695513 s] RESIDENTIAL:                   1194\n",
      "[2021-05-28 11:25:48.006859 | +31.08174 s] CAMPUS + CLOUD:                505\n",
      "[2021-05-28 11:26:10.297593 | +22.290734 s] CAMPUS + RESIDENTIAL:          161\n",
      "[2021-05-28 11:26:30.252701 | +19.955108 s] CLOUD + RESIDENTIAL:           241\n",
      "[2021-05-28 11:26:57.257614 | +27.004913 s] CAMPUS + CLOUD + RESIDENTIAL:  124\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_ip = {\n",
    "    CA: dfLog.select(\"ip\").where(\"origin='campus'\").distinct(),\n",
    "    CL: dfLog.select(\"ip\").where(\"origin='cloud'\").distinct(),\n",
    "    RE: dfLog.select(\"ip\").where(\"origin='residential'\").distinct(),\n",
    "}\n",
    "\n",
    "df_ip[CA_CL] = df_ip[CA].intersect(df_ip[CL])\n",
    "df_ip[CA_RE] = df_ip[CA].intersect(df_ip[RE])\n",
    "df_ip[CL_RE] = df_ip[CL].intersect(df_ip[RE])\n",
    "df_ip[ALL] = df_ip[CA_CL].intersect(df_ip[RE])\n",
    "\n",
    "log(f\"CAMPUS:                        {df_ip[CA].count()}\")\n",
    "log(f\"CLOUD:                         {df_ip[CL].count()}\")\n",
    "log(f\"RESIDENTIAL:                   {df_ip[RE].count()}\")\n",
    "log(f\"CAMPUS + CLOUD:                {df_ip[CA_CL].count()}\")\n",
    "log(f\"CAMPUS + RESIDENTIAL:          {df_ip[CA_RE].count()}\")\n",
    "log(f\"CLOUD + RESIDENTIAL:           {df_ip[CL_RE].count()}\")\n",
    "log(f\"CAMPUS + CLOUD + RESIDENTIAL:  {df_ip[ALL].count()}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116.110.68.228\n",
      "209.141.56.73\n",
      "164.52.24.179\n",
      "116.106.16.84\n",
      "88.166.170.133\n",
      "209.141.62.52\n",
      "221.131.165.56\n",
      "107.131.14.238\n",
      "167.71.0.98\n",
      "167.71.15.34\n",
      "185.213.155.169\n",
      "45.129.56.200\n",
      "222.187.238.136\n",
      "141.98.10.193\n",
      "221.181.185.159\n",
      "165.227.229.167\n",
      "171.226.5.243\n",
      "185.36.81.184\n",
      "5.2.69.42\n",
      "194.165.16.109\n",
      "185.220.102.247\n",
      "62.210.125.141\n",
      "192.42.116.14\n",
      "195.133.40.139\n",
      "116.98.164.231\n",
      "5.188.206.102\n",
      "45.153.160.134\n",
      "162.247.74.201\n",
      "209.141.54.56\n",
      "222.186.42.137\n",
      "31.210.21.37\n",
      "205.185.114.251\n",
      "222.186.180.130\n",
      "189.113.131.44\n",
      "209.127.17.242\n",
      "5.188.206.54\n",
      "193.27.228.233\n",
      "185.220.102.4\n",
      "77.247.181.165\n",
      "221.181.185.19\n",
      "5.2.69.50\n",
      "222.168.30.19\n",
      "5.188.206.100\n",
      "116.110.71.155\n",
      "185.191.124.143\n",
      "5.188.206.98\n",
      "185.220.102.250\n",
      "18.27.197.252\n",
      "195.133.40.214\n",
      "91.138.27.127\n",
      "195.133.40.141\n",
      "205.185.114.91\n",
      "221.181.185.143\n",
      "222.186.42.213\n",
      "167.71.9.148\n",
      "199.19.225.14\n",
      "205.185.119.198\n",
      "116.98.168.101\n",
      "205.185.120.95\n",
      "195.154.56.235\n",
      "222.187.239.109\n",
      "185.220.102.252\n",
      "138.68.185.214\n",
      "193.169.254.234\n",
      "209.141.59.243\n",
      "185.216.32.130\n",
      "171.232.253.241\n",
      "200.216.31.148\n",
      "116.110.96.118\n",
      "185.36.81.182\n",
      "36.112.171.51\n",
      "36.92.109.147\n",
      "209.141.49.67\n",
      "129.146.252.200\n",
      "195.133.40.138\n",
      "221.181.185.135\n",
      "5.188.206.101\n",
      "185.220.102.242\n",
      "5.188.206.99\n",
      "178.73.215.171\n",
      "182.161.55.66\n",
      "209.141.36.52\n",
      "209.141.49.16\n",
      "185.220.102.251\n",
      "62.210.37.82\n",
      "221.181.185.220\n",
      "185.220.102.253\n",
      "205.185.114.222\n",
      "194.165.16.107\n",
      "209.141.59.90\n",
      "45.133.1.158\n",
      "167.71.0.205\n",
      "195.206.105.217\n",
      "116.103.242.175\n",
      "194.165.16.89\n",
      "222.186.30.76\n",
      "171.25.193.78\n",
      "200.216.37.68\n",
      "221.181.185.153\n",
      "185.191.124.151\n",
      "167.71.15.122\n",
      "116.105.213.83\n",
      "205.185.117.246\n",
      "194.165.16.108\n",
      "185.36.81.58\n",
      "91.160.19.34\n",
      "221.181.185.223\n",
      "116.110.21.166\n",
      "116.98.171.233\n",
      "91.132.147.168\n",
      "194.233.65.48\n",
      "222.187.232.205\n",
      "221.181.185.198\n",
      "185.36.81.186\n",
      "194.26.29.28\n",
      "194.165.16.106\n",
      "194.165.16.105\n",
      "176.111.173.88\n",
      "128.199.205.98\n",
      "209.141.62.237\n",
      "209.97.171.251\n",
      "222.186.30.112\n",
      "185.220.102.241\n",
      "185.220.102.243\n"
     ]
    }
   ],
   "source": [
    "for r in df_ip[ALL].collect():\n",
    "    print(r.ip)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
